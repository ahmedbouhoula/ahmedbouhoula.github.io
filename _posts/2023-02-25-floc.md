---
layout: post
title: "Checking Websites' GDPR Consent Compliance for Marketing Emails"
abstract: "Recently proposed systems aim at achieving privacy using locality-sensitive hashing. We show how these approaches fail by presenting attacks against two such systems: Google's FLoC proposal for privacy-preserving targeted advertising and the MinHash Hierarchy, a system for processing mobile users' traffic behavior in a privacy-preserving way. Our attacks refute the pre-image resistance, anonymity, and privacy guarantees claimed for these systems.

In the case of FLoC, we show how to deanonymize users using Sybil attacks and to reconstruct 10% or more of the browsing history for 30% of its users using Generative Adversarial Networks. We achieve this only analyzing the hashes used by FLoC. For MinHash, we precisely identify the movement of a subset of individuals and, on average, we can limit users' movement to just 10% of the possible geographic area, again using just the hashes. In addition, we refute their differential privacy claims."
authors: Florian Turati, Carlos Cotrini, Karel Kubicek, David Basin
publisher: Submitted to Proceedings on Privacy Enhancing Technologies, PETS, 2023.
categories: FLoC privacy
keywords: LSH, FLoC, MinHash, SimHash, Privacy
---

# Locality-Sensitive Hashing Does Not Guarantee Privacy! Attacks on Google's FLoC and the MinHash Hierarchy System

**Authors: Florian Turati, Carlos Cotrini, Karel Kubicek <karel.kubicek@inf.ethz.ch>, and David Basin**

**Abstract:** *Recently proposed systems aim at achieving privacy using locality-sensitive hashing. We show how these approaches fail by presenting attacks against two such systems: Google's FLoC proposal for privacy-preserving targeted advertising and the MinHash Hierarchy, a system for processing mobile users' traffic behavior in a privacy-preserving way. Our attacks refute the pre-image resistance, anonymity, and privacy guarantees claimed for these systems.*

*In the case of FLoC, we show how to deanonymize users using Sybil attacks and to reconstruct 10% or more of the browsing history for 30% of its users using Generative Adversarial Networks. We achieve this only analyzing the hashes used by FLoC. For MinHash, we precisely identify the movement of a subset of individuals and, on average, we can limit users' movement to just 10% of the possible geographic area, again using just the hashes. In addition, we refute their differential privacy claims.*

* Download author pre-print of the paper: [PDF](https://karelkubicek.github.io/assets/pdf/Locality-Sensitive_Hashing_Does_Not_Guarantee_Privacy__Attacks_on_Google_FLoC_and_the_MinHash_Hierarchy_System.pdf)
* Source code and supplementary material: [GitHub](https://github.com/privacy-lsh/floc-minhash) (anonymized version while in review, check [Florian Turati's GitHub page](https://github.com/fturati/))
* Florian Turati's MSc thesis about FLoC: [PDF](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/539945/Thesis_TURATI.pdf)

### Bibtex

```latex
TBA
```

### Locality-Sensitive Hashing not only in Google FLoC

The key idea of FLoC is to take the user's browsing history, and create a 50-bit hash (fingerprint) of it locally in the browser using LSH. This hash is then used to cluster users with similar history, assigning them a cluster ID. Only this ID is then shared with trackers and advertisers, keeping the web content still targeted, but to a groups of at least *k > 2000* users in cluster, providing *k*-anonymity.

LSH maps similar inputs to similar outputs. It is a neat method for clustering and detection of duplicates. Google used one of its flavors in detecting duplicate websites.

After a failed test on tens of millions of users Google discontinued FLoC in 2022, unlucky for our research, but good for users. Yet LSH is still being proposed to other privacy projects. We evaluate the information leakage of LSH in systems that use it to establish privacy - FLoC and MinHash Hierarchy systems.

### FLoC

The key idea of FLoC is to take user's browsing history, and create a 50-bit hash (fingerprint) of it locally in browser using LSH. This hash is then used to cluster users with similar history, assigning them a cluster ID. Only this ID is then shared with trackers and advertisers, keeping the content still targeted, but to a groups of at least *k > 2000* users in cluster, providing *k*-anonymity.

We propose these attacks on FLoC:

1. **Sybil attack:** LSH is unlike cryptographic hash function resistant to finding pre-images (input that maps on target output). We use integer programing to find pre-images in less than a second, allowing us to generate thousands of fake users that can fill cohort and break *k*-anonymity.
2. **GAN-IP attack:** Using Generative Adversarial Networks (GAN), we are able to generate plausible-looking browsing histories capturing behavior patterns of real users. While this generated history does not match the SimHash of the target user, we then use the integer programming to reduce the history to match the target hash. The GAN-IP attack can reconstruct 10% or more of the history in at least 30% of the cases, breaking FLoCâ€™s guarantees of keeping browsing histories private. We compare the attack to the baseline of random guessing of histories and find significantly more information reconstructed by our GAN-IP attack.

![Recovered histories](https://karelkubicek.github.io/assets/images/floc/floc_history_noip.png){: style="float: left; width:50%"}![Recovered histories](https://karelkubicek.github.io/assets/images/floc/floc_history_ip.png){: style="float: left;width:50%;margin-bottom: 100px;margin-top: 100px;"}
*Distribution of overlap between target user's history and generated histories by GAN (left) and GAN-IP (right) attack. While the integer programming reduces the absolute number of recovered history items, the relative portion of history the attack correctly found increases from 8% to 12%. Note that for privacy reasons, we worked with public MovieLens Datasets.*


### MinHash Hierarchy

[MinHash Hierarchy](https://dl.acm.org/doi/abs/10.1145/3055031.3055076) is a system for urban planning. It collects cellular data tracking movement of people in the city to extract statistics about citizens' behavior. It uses LSH to keep the individual's data private, even claiming that it achieves differential privacy.

We show that the differential privacy claims are wrong, since some citizens can be completely tracked. We again evaluate the information leakage from recovering hash pre-images, and we find that in a city as Porto, we can track users down to 10% of area.

![Recovered trajectories](https://karelkubicek.github.io/assets/images/floc/minhash_trajectories1.png){: style="float: left; width:50%"}![Recovered trajectories](https://karelkubicek.github.io/assets/images/floc/minhash_trajectories1.png){: style="float: left;width:50%;margin-bottom: 100px;margin-top: 100px;"}
*Four randomly chosen trajectories of taxi drivers in Porto denoted as "Target X," and the extracted location "Recovered X" from MinHash Hierarchy system. Gray pixels denote where the drivers potentially drove, while black pixels are places where we are certain that the driver passed by. This uses only the LSH hash content, a further post processing on geographical distribution of timestamps would narrow this map significantly more.*

### Conclusions

We show that using locality-sensitive hashing to establish privacy into a data-collection system is a wrong idea. While hashing is lossy compression, there must remain input leakage in the hash, else LSH would not provide any utility. Obliviousness of this leakage to system designers does not mean there is none, and it resembles security by obscurity principle.

There were other systems that use LSH to establish privacy in the system, such as [Apple CSAM](https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf) (discontinued after [attacks were discovered](https://techcrunch.com/2021/08/18/apples-csam-detection-tech-is-under-fire-again/)) and [Replacement AutoEncoder](https://arxiv.org/abs/1710.06564). We are therefore worried if this idea is not a reappearing idea so we use our findings to discourage any privacy system designers from its usage.


### Q&A

* **Q:** Are users of Chrome in danger?

  **A:** No, Google stopped testing FLoC with Chrome v.91, and discontinued the project completely in [January 2022](https://techcrunch.com/2022/01/25/google-kills-off-floc-replaces-it-with-topics/). While we did not analyze Topics API in as much detail as FLoC, it is at least not prone to a similar attack as we show in this work.


### Acknowledgement

The authors would like to thank:

 * [Hung Hoang](https://ch.linkedin.com/in/hung-hoang-5b253a9a) for his advice on integer programming, without him we would still be using naive heuristic by orders of magnitude slower.
 * [Matteo Scarlata](https://hjkl.space/) for his valuable feedback on the draft.
 * MinHash Hierarchy authors for providing us with the implementation of the MinHash signature  computation in their system.

### Updates

* *February 25, 2023:* The initial version of this page.
